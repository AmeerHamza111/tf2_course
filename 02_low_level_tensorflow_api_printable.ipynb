{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Low-Level TensorFlow API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will learn how to use TensorFlow's low-level API, then use it to build custom loss functions, as well as custom Keras layers and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "matplotlib 3.0.2\n",
      "numpy 1.15.4\n",
      "pandas 0.24.0\n",
      "sklearn 0.20.2\n",
      "tensorflow 2.0.0-dev20190124\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(\"python\", sys.version)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 5) # Python ≥3.5 required\n",
    "assert tf.__version__ >= \"2.0\"    # TensorFlow ≥2.0 required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can browse through the code examples or jump directly to the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=15, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=19, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To/From NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22, shape=(2, 3), dtype=float64, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=26, shape=(), dtype=float32, numpy=2.718>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(2.718)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute Add as input #0(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Add] name: add/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(1) + tf.constant(1.0)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute Add as input #0(zero-based) was expected to be a float tensor but is a double tensor [Op:Add] name: add/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(1.0, dtype=tf.float64) + tf.constant(1.0)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36, shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(1.0, dtype=tf.float64)\n",
    "tf.cast(t, tf.float32) + tf.constant(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=38, shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(\"café\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40, shape=(), dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(t, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=47, shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(t, \"UTF8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=50, shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(t, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.RaggedTensor(values=tf.Tensor(\n",
       "[   67    97   102   233    67   111   102   102   101   101    99    97\n",
       "   102   102   232 21654 21857], shape=(17,), dtype=int32), row_splits=tf.Tensor([ 0  4 10 15 17], shape=(5,), dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(t, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.RaggedTensor(values=tf.Tensor([11 12 21 22 23 41], shape=(6,), dtype=int32), row_splits=tf.Tensor([0 2 5 5 6], shape=(5,), dtype=int64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.ragged.constant([[11, 12], [21, 22, 23], [], [41]])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12], [21, 22, 23], [], [41]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([21 22 23], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[21, 22, 23]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12], [21, 22, 23], [], [41], [51, 52], [], [71]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[51, 52], [], [71]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12, 13, 14, 15], [21, 22, 23, 24], [], [41, 42, 43]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[13, 14, 15], [24], [], [42, 43]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=281, shape=(4, 3), dtype=int32, numpy=\n",
       "array([[11, 12,  0],\n",
       "       [21, 22, 23],\n",
       "       [ 0,  0,  0],\n",
       "       [41,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=290, shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=295, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] = [0,1] is out of order [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=310, shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=323, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 7.,  8.,  9.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1].assign([7., 8., 9.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,   5.,   6.],\n",
       "       [  1.,   2., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    t = tf.constant([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/job:localhost/replica:0/task:0/device:CPU:0'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        t2 = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "    print(t2.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 – Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1)\n",
    "Create an `my_mse()` function with two arguments: the true labels `y_true` and the model predictions `y_pred`. Make it return the mean squared error using TensorFlow operations. Note that you could write your own custom metrics in exactly the same way. **Tip**: recall that the MSE is the mean of the squares of prediction errors, which are the differences between the predictions and the labels, so you will need to use `tf.reduce_mean()` and `tf.square()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2)\n",
    "Compile your model, passing it your custom loss function, then train it and evaluate it. **Tip**: don't forget to use the scaled sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb8b049dac8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160==============================] - 0s 27us/sample - loss: 0.4692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46920335967411364"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3)\n",
    "Try building and compiling the model again, this time adding `\"mse\"` (or equivalently `\"mean_squared_error\"` or `keras.losses.mean_squared_error`) to the list of additional metrics, then train the model and make sure the `my_mse` is equal to the standard `mse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160==============================] - 0s 39us/sample - loss: 0.4548 - mean_squared_error: 0.4548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4547801451165547, 0.45478037]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(loss=my_mse, optimizer=\"sgd\", metrics=[\"mean_squared_error\"])\n",
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid), verbose=0)\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4)\n",
    "If you want your code to be portable to other Python implementations of the Keras API, you should use the operations in `keras.backend` rather than TensorFlow operations directly. This package contains thin wrappers around the backend's operations (for example, `keras.backend.square()` simply calls `tf.square()`). Try reimplementing the `my_mse()` function this way and use it to train and evaluate your model again. **Tip**: people frequently define `K = keras.backend` to make their code more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_portable_mse(y_true, y_pred):\n",
    "    K = keras.backend\n",
    "    return K.mean(K.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160==============================] - 0s 42us/sample - loss: 0.4683 - mean_squared_error: 0.4683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46828289226044056, 0.46828288]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(loss=my_portable_mse, optimizer=\"sgd\", metrics=[\"mean_squared_error\"])\n",
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid), verbose=0)\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 – Custom layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1)\n",
    "Some layers have no weights, such as `keras.layers.Flatten` or `keras.layers.ReLU`. If you want to create a custom layer without any weights, the simplest option is to create a `keras.layers.Lambda` layer and pass it the function to perform. For example, try creating a custom layer that applies the softplus function (log(exp(X) + 1), and try calling this layer like a regular function.\n",
    "\n",
    "**Tip**: you can use `tf.math.softplus()` rather than computing the log and the exponential manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_softplus = keras.layers.Lambda(lambda X: tf.nn.softplus(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=106990, shape=(5,), dtype=float32, numpy=\n",
       "array([4.5417706e-05, 6.7153489e-03, 6.9314718e-01, 5.0067153e+00,\n",
       "       1.0000046e+01], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_softplus([-10., -5., 0., 5., 10.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2)\n",
    "Create a regression model like in exercise 1, but add your softplus layer at the top (i.e., after the existing 1-unit dense layer). This can be useful to ensure that your model never predicts negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160==============================] - 0s 29us/sample - loss: 0.4599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45991045208864434"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "    my_softplus\n",
    "])\n",
    "model.compile(loss=my_portable_mse, optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid), verbose=0)\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3)\n",
    "Alternatively, try using this softplus layer as the activation function of the output layer.\n",
    "\n",
    "**Notes**:\n",
    "* setting a layer's activation function is just a handy way of adding an extra weightless layer.\n",
    "* Keras supports the softplus activation function out of the box:\n",
    "  * set `activation=\"softplus\"`\n",
    "  * or set `activation=keras.activations.softplus`\n",
    "  * or add a `keras.layers.Activation(\"softplus\")` layer to your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160==============================] - 0s 32us/sample - loss: 0.5035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.503474702206693"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1, activation=my_softplus)\n",
    "#   A few alternatives...\n",
    "#   keras.layers.Dense(1, activation=tf.function(lambda X: my_softplus(X)))\n",
    "#   keras.layers.Dense(1, activation=\"softplus\")\n",
    "#   keras.layers.Dense(1, activation=keras.activations.softplus)\n",
    "#   keras.layers.Dense(1), keras.layers.Activation(\"softplus\")\n",
    "])\n",
    "\n",
    "model.compile(loss=my_portable_mse, optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid), verbose=0)\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4)\n",
    "Now let's create a custom layer with its own weights. Use the following template to create a `MyDense` layer that computes $\\phi(\\mathbf{X} \\mathbf{W}) + \\mathbf{b}$, where $\\phi$ is the (optional) activation function, $\\mathbf{X}$ is the input data, $\\mathbf{W}$ represents the kernel (i.e., connection weights), and $\\mathbf{b}$ represents the biases, then train and evaluate a model using this instead of a regular `Dense` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tips**:\n",
    "* The constructor `__init__()`:\n",
    "  * It must have all your layer's hyperparameters as arguments, and save them to instance variables. You will need the number of `units` and the optional `activation` function. To support all kinds of activation functions (strings or functions), simply create a `keras.layers.Activation` passing it the `activation` argument.\n",
    "  * The `**kwargs` argument must be passed to the base class's constructor (`super().__init__()`) so your class can support the `input_shape` argument, and more.\n",
    "* The `build()` method:\n",
    "  * The `build()` method will be called automatically by Keras when it knows the shape of the inputs. Note that the argument should really be called `batch_input_shape` since it includes the batch size.\n",
    "  * You must call `self.add_weight()` for each weight you want to create, specifying its `name`, `shape` (which often depends on the `input_shape`), how to initialize it, and whether or not it is `trainable`. You need two weights: the `kernel` (connection weights) and the `biases`. The kernel must be initialized randomly. The biases are usually initialized with zeros. **Note**: you can find many initializers in `keras.initializers`.\n",
    "  * Do not forget to call `super().build()`, so Keras knows that the model has been built.\n",
    "  * Note: you could create the weights in the constructor, but it is preferable to create them in the `build()` method, because users of your class may not always know the `input_shape` when creating the model. The first time the model is used on some actual data, the `build()` method will automatically be called with the actual `input_shape`.\n",
    "* The `call()` method:\n",
    "  * This is where to code your layer's actual computations. As before, you can use TensorFlow operations directly, or use `keras.backend` operations if you want the layer to be portable to other Keras implementations.\n",
    "* The `compute_output_shape()` method:\n",
    "  * You do not need to implement this method when using tf.keras, as the `Layer` class provides a good implementation.\n",
    "  * However, if want to port your code to another Keras implementation (such as keras-team), and if the output shape is different from the input shape, then you need to implement this method. Note that the input shape is actually the batch input shape, and the ouptut shape must be the batch output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = keras.layers.Activation(activation)\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(MyDense, self).build(input_shape)\n",
    "\n",
    "    @tf.function   # required, see https://github.com/tensorflow/tensorflow/issues/25096\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160==============================] - 0s 45us/sample - loss: 0.5592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5591562871785127"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid), verbose=0)\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 – TensorFlow Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1)\n",
    "Examine and run the following code examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_elu(z, scale=1.0, alpha=1.0):\n",
    "    is_positive = tf.greater_equal(z, 0.0)\n",
    "    return scale * tf.where(is_positive, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=193629, shape=(), dtype=float32, numpy=-0.95021296>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_elu(tf.constant(-3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=193639, shape=(2,), dtype=float32, numpy=array([-0.95021296,  2.5       ], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_elu(tf.constant([-3., 2.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7f998c34deb8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_elu_tf = tf.function(scaled_elu)\n",
    "scaled_elu_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=193655, shape=(), dtype=float32, numpy=-0.95021296>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_elu_tf(tf.constant(-3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=193670, shape=(2,), dtype=float32, numpy=array([-0.95021296,  2.5       ], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_elu_tf(tf.constant([-3., 2.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_elu_tf.python_function is scaled_elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.84 ms ± 48.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit scaled_elu(tf.random.normal((1000, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.61 ms ± 17.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit scaled_elu_tf(tf.random.normal((1000, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from __future__ import print_function\n",
       "\n",
       "def tf__scaled_elu(z, scale=None, alpha=None):\n",
       "  try:\n",
       "    with ag__.function_scope('scaled_elu'):\n",
       "      is_positive = tf.greater_equal(z, 0.0)\n",
       "      return scale * tf.where(is_positive, z, alpha * tf.nn.elu(z))\n",
       "  except:\n",
       "    ag__.rewrite_graph_construction_error(ag_source_map__)\n",
       "\n",
       "\n",
       "\n",
       "tf__scaled_elu.autograph_info__ = {}\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(scaled_elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def add_21():\n",
    "    return var.assign_add(21)\n",
    "\n",
    "@tf.function\n",
    "def times_2():\n",
    "    return var.assign(var * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=210741, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_21()\n",
    "times_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times_4(x):\n",
    "    return 4. * x\n",
    "\n",
    "@tf.function\n",
    "def times_4_plus_22(x):\n",
    "    return times_4(x) + 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=210753, shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_4_plus_22(tf.constant(5.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute 1 + 1/2 + 1/4 + ...: the order of execution of the operations with side-effects (e.g., `assign()`) is preserved (in TF 1.x, `tf.control_dependencies()` was needed in such cases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=210839, shape=(), dtype=float32, numpy=1.9999981>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = tf.Variable(0.)\n",
    "increment = tf.Variable(1.)\n",
    "\n",
    "@tf.function\n",
    "def converge_to_2(n_iterations):\n",
    "    for i in tf.range(n_iterations):\n",
    "        total.assign_add(increment)\n",
    "        increment.assign(increment / 2.0)\n",
    "    return total\n",
    "\n",
    "converge_to_2(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2)\n",
    "Write a function that computes the sum of squares from 1 to n, where n is an argument. Convert it to a graph function by using `tf.function` as a decorator. Display the code generated by autograph using the `display_tf_code()` function. Use `%timeit` to see how must faster the TensorFlow `Function` is compared to the Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sum_squares(n):\n",
    "    s = tf.constant(0)\n",
    "    for i in range(1, n + 1):\n",
    "        s = s + i ** 2\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=210910, shape=(), dtype=int32, numpy=55>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_squares(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from __future__ import print_function\n",
       "import tensorflow as tf\n",
       "\n",
       "@tf.function\n",
       "def tf__sum_squares(n):\n",
       "  try:\n",
       "    with ag__.function_scope('sum_squares'):\n",
       "      s = tf.constant(0)\n",
       "\n",
       "      def extra_test(s_1):\n",
       "        with ag__.function_scope('extra_test'):\n",
       "          return True\n",
       "\n",
       "      def loop_body(loop_vars, s_1):\n",
       "        with ag__.function_scope('loop_body'):\n",
       "          i = loop_vars\n",
       "          s_1 = s_1 + i ** 2\n",
       "          return s_1,\n",
       "      s = ag__.for_stmt(ag__.range_(1, n + 1), extra_test, loop_body, (s,))\n",
       "      return s\n",
       "  except:\n",
       "    ag__.rewrite_graph_construction_error(ag_source_map__)\n",
       "\n",
       "\n",
       "\n",
       "tf__sum_squares.autograph_info__ = {}\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(sum_squares.python_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.53 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "162 µs ± 127 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_squares(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233 ms ± 2.27 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_squares.python_function(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3)\n",
    "Examine and run the following code examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def square(x):\n",
    "    print(\"Calling\", x)  # part of the TF Function\n",
    "    tf.get_logger().warning(\"Tracing\")  # NOT part of the TF Function\n",
    "    return tf.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0217 13:53:49.594420 140301240059648 tmpau_d33og.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 0\n",
      "Calling 1\n",
      "Calling 2\n",
      "Calling 3\n",
      "Calling 4\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    square(tf.constant(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:49.704779 140301240059648 tmpe58jrf0m.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 0.0\n",
      "Calling 1.0\n",
      "Calling 2.0\n",
      "Calling 3.0\n",
      "Calling 4.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    square(tf.constant(i, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:49.819299 140301240059648 tmpqy2y7jqv.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling [0. 0.]\n",
      "Calling [1. 1.]\n",
      "Calling [2. 2.]\n",
      "Calling [3. 3.]\n",
      "Calling [4. 4.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    square(tf.constant([i, i], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:50.180286 140301240059648 tmporyao7o2.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:50.294979 140301240059648 tmp_iljwmn3.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:50.403625 140301240059648 tmp624uh8u8.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:50.512877 140301240059648 tmpr4ilir43.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:53:50.621813 140301240059648 tmp0s_tha_k.py:19] Tracing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling 4\n"
     ]
    }
   ],
   "source": [
    "# WARNING: when passing non-tensor values, a trace happens for any new value!\n",
    "# This is to allow optimization in case this value determines e.g., number of layers.\n",
    "for i in range(5):\n",
    "    square(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4)\n",
    "When you give Keras a custom loss function, it actually creates a graph function based on it, and then uses that graph function during training. The same is true of custom metric functions, and the `call()` method of custom layers and models. Create a `my_mse()` function, like you did earlier, but add an instruction to log a message inside it (do *not* use `print()`!), and verify that the message is only logged once when you compile and train the model. Optionally, you can also find out when Keras converts custom metrics, layers and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    tf.get_logger().warning(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    tf.get_logger().warning(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = keras.layers.Activation(activation)\n",
    "        super(MyDense, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super(MyDense, self).build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        tf.get_logger().warning(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        tf.get_logger().warning(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"sgd\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0217 13:54:30.681071 140301240059648 training.py:2703] Tracing MyModel.call()\n",
      "W0217 13:54:30.682790 140301240059648 deprecation.py:506] From /opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:111: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0217 13:54:30.689498 140301240059648 base_layer.py:558] Tracing MyDense.call()\n",
      "W0217 13:54:30.700104 140301240059648 base_layer.py:558] Tracing MyDense.call()\n",
      "W0217 13:54:30.712319 140301240059648 base_layer.py:558] Tracing MyDense.call()\n",
      "W0217 13:54:30.723696 140301240059648 training_utils.py:644] Tracing loss my_mse()\n",
      "W0217 13:54:30.733945 140301240059648 metrics.py:551] Tracing metric my_mae()\n",
      "W0217 13:54:30.745486 140301240059648 training_utils.py:644] Tracing metric my_mae()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610==============================] - 1s 86us/sample - loss: 3.3026 - my_mae: 1.4837 - val_loss: 1.8555 - val_my_mae: 0.9966\n",
      "Epoch 2/2\n",
      "11610/11610==============================] - 1s 69us/sample - loss: 1.2436 - my_mae: 0.7962 - val_loss: 1.3280 - val_my_mae: 0.6464\n",
      "5160/5160==============================] - 0s 36us/sample - loss: 0.8685 - my_mae: 0.6459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8685485477595366, 0.6459101]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each custom function is traced just once, except for the metric function. That's a bit odd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5)\n",
    "Examine the following function, and try to call it with various argument types and shapes. Notice that only tensors of type `int32` and one dimension (of any size) are accepted now that we have specified the `input_signature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.int32, name=\"x\")])\n",
    "def cube(z):\n",
    "    return tf.pow(z, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=400017, shape=(3,), dtype=int32, numpy=array([ 1,  8, 27], dtype=int32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=400020, shape=(5,), dtype=int32, numpy=array([  1,   8,  27,  64, 125], dtype=int32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure of Python function inputs does not match input_signature.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cube([1, 2, 3])\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature: inputs ((<tf.Tensor: id=400022, shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,)), input_signature ((TensorSpec(shape=(None,), dtype=tf.int32, name='x'),))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cube(tf.constant([1., 2., 3]))\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature: inputs ((<tf.Tensor: id=400024, shape=(2, 2), dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]], dtype=int32)>,)), input_signature ((TensorSpec(shape=(None,), dtype=tf.int32, name='x'),))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cube(tf.constant([[1, 2], [3, 4]]))\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 – Function Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1)\n",
    "Examine and run the following code examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.int32, name=\"x\")])\n",
    "def cube(z):\n",
    "    return tf.pow(z, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.function.ConcreteFunction at 0x7f939d660978>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32 = cube.get_concrete_function(tf.TensorSpec([None], tf.int32))\n",
    "cube_func_int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32 is cube.get_concrete_function(tf.TensorSpec([5], tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32 is cube.get_concrete_function(tf.constant([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f939d660748>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2)\n",
    "The function's graph is represented on the following diagram. Call the graph's `get_operations()` method to get the list of operations. Each operation has an `inputs` attribute that returns an iterator over its input tensors (these are symbolic: contrary to tensors we have used up to now, they have no value). It also has an `outputs` attribute that returns the list of output tensors. Each tensor has an `op` attribute that returns the operation it comes from. Try navigating through the graph using these methods and attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cube_graph.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Pow/y' type=Const>,\n",
       " <tf.Operation 'Pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'Pow' type=Pow>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = cube_func_int32.graph.get_operations()[2]\n",
    "pow_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=(None,) dtype=int32>,\n",
       " <tf.Tensor 'Pow/y:0' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_in = list(pow_op.inputs)\n",
    "pow_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Pow:0' shape=(None,) dtype=int32>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_out = list(pow_op.outputs)\n",
    "pow_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=(None,) dtype=int32>,\n",
       " <tf.Tensor 'Pow/y:0' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_in = list(pow_op.inputs)\n",
    "pow_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_in[0].op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3)\n",
    "Each operation has a default name, such as `\"pow\"` (you can override it by setting the `name` attribute when you call the operation). In case of a name conflict, TensorFlow adds an underscore and anindex to make the name unique (e.g. `\"pow_1\"`). Moreover, each tensor has the same name as the operation that outputs it, followed by a colon `:` and the tensor's `index` (e.g., `\"pow:0\"`). Most operations have a single output tensor, so most tensors have a name that ends with `:0`. Try using `get_operation_by_name()` and `get_tensor_by_name()` to access any op and tensor you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.get_operation_by_name(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x:0' shape=(None,) dtype=int32>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.get_tensor_by_name(\"x:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4)\n",
    "Call the graph's `as_graph_def()` method and print the output. This is a protobuf representation of the computation graph: it is what makes TensorFlow models so portable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"x\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"_user_specified_name\"\n",
       "    value {\n",
       "      s: \"x\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Pow/y\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Pow\"\n",
       "  op: \"Pow\"\n",
       "  input: \"x\"\n",
       "  input: \"Pow/y\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"Identity\"\n",
       "  op: \"Identity\"\n",
       "  input: \"Pow\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5)\n",
    "Get the concrete function's `function_def`, and look at its `signature`. This shows the names and types of the nodes in the graph that correspond to the function's inputs and outputs. This will come in handy when you deploy models to TensorFlow Serving or Google Cloud ML Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_400032\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_INT32\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_INT32\n",
       "}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_func_int32.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 – Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1)\n",
    "Examine and run the following code examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3. * x ** 2 + 2. * x - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_derivative(f, x, eps=1e-3):\n",
    "    return (f(x + eps) - f(x - eps)) / (2. * eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximate_derivative(f, 1.0) # true derivative = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(-2, 2, 200)\n",
    "fs = f(xs)\n",
    "x0 = 0.5\n",
    "df_x0 = approximate_derivative(f, x0)\n",
    "tangent_x0 = df_x0 * (xs - x0) + f(x0)\n",
    "plt.plot([-2, 2], [0, 0], \"k-\", linewidth=1)\n",
    "plt.plot([0, 0], [-5, 15], \"k-\", linewidth=1)\n",
    "plt.plot(xs, fs)\n",
    "plt.plot(xs, tangent_x0, \"r--\")\n",
    "plt.plot(x0, f(x0), \"ro\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"x\", fontsize=14)\n",
    "plt.ylabel(\"f(x)\", fontsize=14, rotation=0)\n",
    "plt.axis([-2, 2, -5, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x1, x2):\n",
    "    return (x1 + 5) * (x2 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_gradient(f, x1, x2, eps=1e-3):\n",
    "    df_x1 = approximate_derivative(lambda x: f(x, x2), x1, eps)\n",
    "    df_x2 = approximate_derivative(lambda x: f(x1, x), x2, eps)\n",
    "    return df_x1, df_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.999999999993236, 41.999999999994486)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximate_gradient(g, 2.0, 3.0) # true gradient = (9, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=400058, shape=(), dtype=float32, numpy=9.0>,\n",
       " <tf.Tensor: id=400070, shape=(), dtype=float32, numpy=42.0>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = g(x1, x2)\n",
    "grads = tape.gradient(z, [x1, x2])\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientTape.gradient can only be called once on non-persistent tapes.\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = g(x1, x2)\n",
    "\n",
    "dz_x1 = tape.gradient(z, x1)\n",
    "try:\n",
    "    dz_x2 = tape.gradient(z, x2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=400156, shape=(), dtype=float32, numpy=9.0>,\n",
       " <tf.Tensor: id=400195, shape=(), dtype=float32, numpy=42.0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = g(x1, x2)\n",
    "\n",
    "dz_x1 = tape.gradient(z, x1)\n",
    "dz_x2 = tape.gradient(z, x2)\n",
    "del tape\n",
    "dz_x1, dz_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.constant(2.0) # <= not Variable\n",
    "x2 = tf.constant(3.0) # <= not Variable\n",
    "with tf.GradientTape() as tape:\n",
    "    z = g(x1, x2)\n",
    "\n",
    "grads = tape.gradient(z, [x1, x2])\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=400226, shape=(), dtype=float32, numpy=9.0>,\n",
       " <tf.Tensor: id=400238, shape=(), dtype=float32, numpy=42.0>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.constant(2.0)\n",
    "x2 = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x1)\n",
    "    tape.watch(x2)\n",
    "    z = g(x1, x2)\n",
    "\n",
    "grads = tape.gradient(z, [x1, x2])\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=400295, shape=(), dtype=float32, numpy=13.0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(5.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = 3 * x\n",
    "    z2 = x ** 2\n",
    "tape.gradient([z1, z2], x) # dz1_x + dz2_x = 3 + 2x = 3 + 2*5 = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, <tf.Tensor: id=400358, shape=(), dtype=float32, numpy=6.0>],\n",
       " [<tf.Tensor: id=400412, shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: id=400395, shape=(), dtype=float32, numpy=14.0>]]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(2.0)\n",
    "x2 = tf.Variable(3.0)\n",
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = g(x1, x2)\n",
    "    jacobians = jacobian_tape.gradient(z, [x1, x2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [x1, x2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape\n",
    "hessians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2)\n",
    "Implement Gradient Descent manually to find the value of `x` that minimizes the following function `f(x)`.\n",
    "\n",
    "**Tips**:\n",
    "* Define a variable `x` and initialize it to 0.\n",
    "* Define the `learning_rate` (e.g., 0.1).\n",
    "* Write a loop that will repeatedly (1) compute the gradient of `f` (actually a derivative in this case) at the current value of `x`, and (2) tweak `x` slightly in the opposite direction (by subtracting `learning_rate * df_dx`). You can use `x.assign_sub(...)` for this.\n",
    "* Using calculus, we can find that the algorithm should converge to $x = -\\frac{1}{3}$. Indeed, the derivative of $f(x) = 3 x^2 + 2x -1$ is $f'(x) = 6x + 2$, so the minimum is reached when $f'(x) = 0$ (slope is 0), so $6x + 2 = 0$, which leads to $x = -\\frac{1}{3}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3. * x ** 2 + 2. * x - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.3333333>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "x = tf.Variable(0.0)\n",
    "\n",
    "for iteration in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = f(x)\n",
    "    dz_dx = tape.gradient(z, x)\n",
    "    x.assign_sub(learning_rate * dz_dx)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3)\n",
    "Now use an `SGD` optimizer instead of manually tweaking `x`.\n",
    "\n",
    "**Tips**:\n",
    "* You first need to create an `SGD` optimizer, optionally specifying the learning_rate (e.g., `lr=0.1`).\n",
    "* Next replace the manual tweaking of `x` in your previous code to use `optimizer.apply_gradients()` instead. You need to pass it a list of gradient/variable pairs (just one pair in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-0.3333333>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(0.0)\n",
    "optimizer = keras.optimizers.SGD(lr=0.1)\n",
    "\n",
    "for iteration in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = f(x)\n",
    "    dz_dx = tape.gradient(z, x)\n",
    "    optimizer.apply_gradients([(dz_dx, x)])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4)\n",
    "Create a `Sequential` model for the California housing problem (no need to compile it), and train it using your own training loop, instead of using `fit()`. Evaluate your model on the validation set at the end of each epoch, and display the result.\n",
    "\n",
    "**Tips**:\n",
    "* You can use the following `random_batch()` function to get a new batch of training data at each iteration (the Data API would be much preferable, as we will see in the next notebook).\n",
    "* You can use the model like a function to make predictions: `y_pred = model(X_batch)`\n",
    "* You can use `keras.losses.mean_squared_error()` to compute the loss. Note that it returns one loss per instance, so you need to use `tf.reduce_mean()` to get the mean loss. \n",
    "* You can use `model.trainable_variables` to get the full list of trainable variables in your model.\n",
    "* You can use `zip(gradients, variables)` to create a list containing all the gradient/variable pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size = 32):\n",
    "    idx = np.random.randint(0, len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 valid mse: 10.514079\n",
      "Epoch 1 valid mse: 7.5957823\n",
      "Epoch 2 valid mse: 0.8575303\n",
      "Epoch 3 valid mse: 0.70870006\n",
      "Epoch 4 valid mse: 0.61762285\n",
      "Epoch 5 valid mse: 0.5635681\n",
      "Epoch 6 valid mse: 0.55062544\n",
      "Epoch 7 valid mse: 0.5125756\n",
      "Epoch 8 valid mse: 0.50464547\n",
      "Epoch 9 valid mse: 0.5018674\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step in range(steps_per_epoch):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "    y_pred = model(X_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(loss_fn(y_valid, y_pred))\n",
    "    print(\"Epoch\", epoch, \"valid mse:\", valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5)\n",
    "Examine and run the following code examples, then update your training loop to display the training loss at each iteration.\n",
    "\n",
    "**Tips**:\n",
    "* You can use a `keras.metrics.MeanSquaredError` instance to efficiently track the running mean squared error at each iteration.\n",
    "* Make sure you reset the metric's states at the start of each epoch.\n",
    "* You can use `print(\"\\r\", mse, end=\"\")` to display the MSE on the same line at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=605063, shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = keras.metrics.MeanSquaredError()\n",
    "metric([5.], [2.])  # error = (2 - 5)**2 = 9\n",
    "metric([0.], [1.])  # error = (1 - 0)**2 = 1\n",
    "metric.result()     # mean error = (9 + 1) / 2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=605069, shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.reset_states()\n",
    "metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=605086, shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric([1.], [3.])  # error = (3 - 1)**2 = 4\n",
    "metric.result()     # mean error = 4 / 1 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  train mse: 1.6207398\tvalid mse: 17.008974\n",
      "Epoch 1  train mse: 0.7614396\tvalid mse: 9.84763\n",
      "Epoch 2  train mse: 0.6617865\tvalid mse: 4.783753\n",
      "Epoch 3  train mse: 0.6473666\tvalid mse: 0.61845475\n",
      "Epoch 4  train mse: 0.56790835\tvalid mse: 0.74327624\n",
      "Epoch 5  train mse: 0.56685776\tvalid mse: 0.54980206\n",
      "Epoch 6  train mse: 0.53035283\tvalid mse: 0.60690194\n",
      "Epoch 7  train mse: 0.52254856\tvalid mse: 0.50044566\n",
      "Epoch 8  train mse: 0.50599176\tvalid mse: 0.5285307\n",
      "Epoch 9  train mse: 0.497541\tvalid mse: 0.5259951\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "metric = keras.metrics.MeanSquaredError()  # ADDED\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()  # ADDED\n",
    "    for step in range(steps_per_epoch):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train, batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            metric(y_batch, y_pred)  # ADDED\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        grads_and_vars = zip(grads, model.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print(\"\\rEpoch\", epoch, \" train mse:\", metric.result().numpy(), end=\"\")  # ADDED\n",
    "    y_pred = model(X_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(loss_fn(y_valid, y_pred))\n",
    "    print(\"\\tvalid mse:\", valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to use TensorFlow's low-level API to write custom loss functions, layers, and models. You also learned how to optimize your functions by converting them to graphs: this allows TensorFlow to run operations in parallel and to perform various optimizations. Next, you learned how TensorFlow Functions and graphs are structured, and how to navigate through them. Finally, you learned how to use autodiff and write your own custom training loops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
